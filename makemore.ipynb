{"cells":[{"cell_type":"markdown","metadata":{"id":"zwSp_9w5hiNH"},"source":["# **makemore** character level language model"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["32033"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["words = open('names.txt', 'r').read().splitlines()\n","len(words)"]},{"cell_type":"markdown","metadata":{},"source":["### summary of the full network"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["chars = sorted(list(set(''.join(words))))\n","stoi = {s:i+1 for i, s in enumerate(chars)}\n","stoi['.'] = 0\n","itos = {i:s for s, i in stoi.items()}"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["X, Y = [], []\n","block_size = 3\n","\n","for w in words:\n","    context = [0] * block_size\n","    for ch in w + '.':\n","        ix = stoi[ch]\n","        X.append(context)\n","        Y.append(ix)\n","        context = context[1:] + [ix]\n","\n","X = torch.tensor(X)\n","Y = torch.tensor(Y)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["X.shape, X.dtype, Y.shape, Y.dtype"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["g = torch.Generator().manual_seed(2147483647)\n","C = torch.randn((27, 2), generator=g)\n","W1 = torch.randn((6, 100), generator=g)\n","b1 = torch.randn(100, generator=g)\n","W2 = torch.randn((100, 27), generator=g)\n","b2 = torch.randn(27, generator=g)\n","parameters = [C, W1, b1, W2, b2]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["3481"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["sum(p.nelement() for p in parameters)"]},{"cell_type":"markdown","metadata":{},"source":["### training on the full dataset, minibatches"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for p in parameters:\n","    p.requires_grad = True"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loss = 2.2970592975616455\n"]}],"source":["for _ in range(1000):\n","\n","    # mini-batch construct\n","    ix = torch.randint(0, X.shape[0], (32,))\n","\n","    # forward pass\n","    emb = C[X[ix]]\n","    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n","    logits = h @ W2 + b2\n","    loss = F.cross_entropy(logits, Y[ix])\n","\n","    # backward pass\n","    for p in parameters:\n","        p.grad = None\n","    loss.backward()\n","\n","    # update\n","    for p in parameters:\n","        p.data += -0.1*p.grad\n","\n","print(f'loss = {loss.item()}')\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loss = 2.676436424255371\n"]}],"source":["emb = C[X]\n","h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n","logits = h @ W2 + b2\n","loss = F.cross_entropy(logits, Y)\n","print(f'loss = {loss.item()}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP9t5JITPjbvYZp1vLK+VGG","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
