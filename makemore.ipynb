{"cells":[{"cell_type":"markdown","metadata":{"id":"zwSp_9w5hiNH"},"source":["# **makemore** character level language model"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["['emma', 'olivia', 'ava', 'isabella', 'sophia']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["words = open('names.txt', 'r').read().splitlines()\n","words[:5]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["32033"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["len(words)"]},{"cell_type":"markdown","metadata":{},"source":["### (re-)building our training dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# create the vocabulary of characters and mappings to/from integers\n","chars = sorted(list(set(''.join(words))))\n","stoi = {s:i+1 for i, s in enumerate(chars)}\n","stoi['.'] = 0\n","itos = {i:s for s, i in stoi.items()}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["emma\n","... -----> e\n","..e -----> m\n",".em -----> m\n","emm -----> a\n","mma -----> .\n","olivia\n","... -----> o\n","..o -----> l\n",".ol -----> i\n","oli -----> v\n","liv -----> i\n","ivi -----> a\n","via -----> .\n","ava\n","... -----> a\n","..a -----> v\n",".av -----> a\n","ava -----> .\n"]}],"source":["# build the dataset\n","\n","block_size = 3\n","X, Y = [], []\n","\n","for w in words[:3]:\n","    print(w)\n","    context = [0] * block_size\n","    for ch in w + '.':\n","        ix = stoi[ch]\n","        X.append(context)\n","        Y.append(ix)\n","        print(''.join(itos[i] for i in context), '----->', itos[ix])\n","        context = context[1:] + [ix]\n","\n","X = torch.tensor(X)\n","Y = torch.tensor(Y)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([16, 3]), torch.int64, torch.Size([16]), torch.int64)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["X.shape, X.dtype, Y.shape, Y.dtype"]},{"cell_type":"markdown","metadata":{},"source":["### implementing the embedding lookup table"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[-7.1580e-01,  4.0690e-01],\n","        [-1.1244e+00, -9.0459e-01],\n","        [-1.9700e-01,  2.1793e+00],\n","        [ 1.7969e+00, -2.4572e+00],\n","        [ 2.3304e-01, -1.9314e+00],\n","        [ 7.4945e-01, -2.7370e-02],\n","        [-6.1758e-01, -8.8516e-01],\n","        [ 1.5348e+00, -1.4031e+00],\n","        [ 1.4703e+00, -2.0701e-01],\n","        [-1.7259e+00, -1.0940e+00],\n","        [ 2.2821e+00,  4.4190e-01],\n","        [-2.0759e+00,  1.4705e-03],\n","        [ 1.5831e+00, -1.1907e-01],\n","        [-1.5216e+00,  4.9696e-01],\n","        [ 1.1044e-01,  2.2362e+00],\n","        [-2.7097e-01,  1.1891e+00],\n","        [ 1.3408e+00, -1.8662e-01],\n","        [ 8.9310e-01, -7.5095e-01],\n","        [ 1.9594e+00,  7.5707e-01],\n","        [ 2.6810e-01,  1.2227e+00],\n","        [ 4.0545e-01, -7.4810e-01],\n","        [ 3.4169e-01,  1.4539e-01],\n","        [-9.1193e-01, -1.5951e+00],\n","        [-6.7749e-01,  6.0704e-01],\n","        [-1.7167e+00,  5.0638e-01],\n","        [ 2.7915e-01,  7.9710e-01],\n","        [-8.2932e-01,  4.8390e-01]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["C = torch.randn((27,2))\n","C"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([16, 3, 2])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["emb = C[X]\n","emb.shape"]},{"cell_type":"markdown","metadata":{},"source":["### implementing the hidden layer"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["W1 = torch.randn((3*2, 100))\n","b = torch.randn(100)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[-0.9951,  0.5747, -0.9827,  ..., -0.9376, -0.8562,  0.9340],\n","        [-0.9779, -0.8262, -0.8964,  ...,  0.1763,  0.8308,  0.7574],\n","        [-0.6151,  0.9992,  0.5792,  ..., -0.9999, -0.6048,  0.7760],\n","        ...,\n","        [-0.9974, -0.8666, -0.9153,  ..., -0.9979, -0.9964,  0.7982],\n","        [-0.9945, -0.9876, -0.4220,  ..., -0.9971, -0.9914,  0.4066],\n","        [-0.8570, -0.2889,  0.5530,  ..., -0.9948, -0.6066,  0.8962]])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["h = emb.view(emb.shape[0], 6) @ W1 + b\n","h = torch.tanh(h)\n","h"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([16, 100])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["h.shape"]},{"cell_type":"markdown","metadata":{},"source":["### implementing the output layer"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["W2 = torch.randn((100, 27))\n","b = torch.randn(27)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[-7.6892e+00, -1.2921e+01, -5.5874e-01, -3.7206e+00, -1.2567e+01,\n","         -5.1561e+00, -5.2286e+00,  1.7415e-02,  3.4478e+00,  4.2923e-01,\n","         -2.6775e+00,  6.2969e+00, -1.4304e+00, -7.0164e+00,  1.5239e+01,\n","          6.2397e+00, -1.2713e+01, -5.9553e+00,  1.2132e+00, -9.0699e+00,\n","         -1.8321e+01, -4.2600e+00, -4.9258e-01,  4.9596e+00, -5.9961e+00,\n","          8.1291e+00, -4.1215e+00],\n","        [-1.1738e+01, -1.2997e+01, -6.6406e-01, -1.6535e+00, -1.7980e+01,\n","         -1.0893e+01, -1.1606e+01, -1.2615e+01,  6.5770e+00,  9.8676e-01,\n","         -8.4918e-01,  9.5937e+00, -1.9253e+00, -1.1588e+01,  6.4213e+00,\n","          5.2779e+00, -2.2500e+00, -5.9052e+00, -1.8445e+01, -1.6116e+01,\n","         -9.2384e+00,  5.4796e+00,  7.0828e-01, -9.4454e+00, -3.4156e+00,\n","          1.5204e+00, -2.7699e+00],\n","        [ 1.9602e+00, -9.9869e+00, -1.6924e+00, -2.3282e+00, -4.7702e+00,\n","         -1.1964e+00,  4.6112e+00,  2.3050e+00,  5.2753e+00, -5.0789e+00,\n","         -8.0262e+00, -6.1355e+00, -3.8588e+00, -5.3836e+00,  8.0352e+00,\n","          8.9673e+00, -1.3668e+01,  3.1857e+00,  1.2382e+01,  2.8077e+00,\n","         -1.0909e+01, -1.2567e+01,  1.1857e+01,  7.3109e+00,  3.5729e+00,\n","          2.7927e+00,  2.0048e+00],\n","        [ 1.4856e+00, -8.0802e+00,  1.4455e+01,  2.8200e-01,  4.7406e+00,\n","         -1.1097e+01,  1.9993e+00,  2.1982e+00, -3.4748e+00,  6.2862e+00,\n","         -9.7553e+00,  1.3167e+01, -1.4345e+00,  3.6324e+00,  1.0179e+01,\n","         -2.7531e+00, -4.3851e+00, -6.8463e+00,  1.3621e+01, -7.1327e+00,\n","         -6.2222e+00, -1.9993e+00, -1.5381e+01,  1.2044e+01, -3.3011e+00,\n","         -3.6945e+00, -2.0508e+01],\n","        [-2.1501e+01, -1.6216e+01, -5.8326e+00, -3.1226e+00, -1.5200e+01,\n","         -1.0593e+01, -6.3255e+00,  1.2355e+00,  6.9422e+00, -1.6083e-01,\n","          5.5263e+00, -1.3712e+00, -3.8271e-01, -1.6855e+01,  8.6135e+00,\n","          8.8082e-01, -1.1244e+01, -2.7088e+00, -6.5110e-01, -1.4237e+01,\n","         -1.3414e+01, -6.6698e+00, -4.3910e+00,  4.8655e+00, -1.4765e+00,\n","          4.3841e+00, -4.6564e+00],\n","        [-7.6892e+00, -1.2921e+01, -5.5874e-01, -3.7206e+00, -1.2567e+01,\n","         -5.1561e+00, -5.2286e+00,  1.7415e-02,  3.4478e+00,  4.2923e-01,\n","         -2.6775e+00,  6.2969e+00, -1.4304e+00, -7.0164e+00,  1.5239e+01,\n","          6.2397e+00, -1.2713e+01, -5.9553e+00,  1.2132e+00, -9.0699e+00,\n","         -1.8321e+01, -4.2600e+00, -4.9258e-01,  4.9596e+00, -5.9961e+00,\n","          8.1291e+00, -4.1215e+00],\n","        [ 7.6864e-01, -1.0088e+01,  3.4167e-01, -1.2189e+00, -5.8635e+00,\n","         -2.6480e+00, -3.7516e+00, -6.7928e+00,  3.4904e+00,  4.1658e+00,\n","         -8.3388e+00,  5.1233e+00,  1.4540e+00, -2.3544e+00,  1.6019e+01,\n","          1.0621e+01, -7.3812e+00, -6.4661e+00, -9.1638e+00, -4.8415e+00,\n","         -1.6427e+01,  6.0293e+00, -4.2510e-01,  1.6621e+00, -5.6690e+00,\n","          8.2363e+00, -1.6827e+00],\n","        [-1.0607e+01, -8.0019e+00,  1.2817e+00, -9.7263e+00, -1.9775e+01,\n","         -7.1170e+00, -1.5282e+01, -1.2032e+01,  7.3900e+00,  6.5069e+00,\n","         -2.5547e+00,  6.6406e+00, -6.1112e-01, -1.0596e+01,  5.8445e+00,\n","          5.4898e+00,  5.2289e+00, -8.0128e+00, -2.6187e+01, -1.6385e+01,\n","         -1.5962e+00,  8.9819e+00,  3.5048e+00, -7.4135e+00, -5.3112e-02,\n","         -1.0765e+00, -2.2112e-01],\n","        [ 8.6349e+00, -7.1006e+00,  3.4908e+00, -3.4981e+00, -9.4412e+00,\n","         -4.5420e+00,  3.5175e+00,  3.4177e+00,  1.0286e+01, -6.4728e+00,\n","         -8.6248e+00, -1.4790e+01, -2.3827e+00, -6.7988e+00,  2.7448e+00,\n","          4.0672e+00, -9.2126e+00, -1.1504e+01,  8.7345e+00, -8.1811e-01,\n","         -5.0045e+00, -8.6981e+00,  1.1608e+01,  1.0264e+01,  1.1354e+01,\n","          2.2322e+00, -4.7542e+00],\n","        [-2.5097e+00,  3.2094e+00,  1.0521e+01,  8.3482e+00,  1.4344e+00,\n","         -1.3893e+01,  8.6159e-01, -9.4918e-01,  5.6021e+00,  2.6313e+00,\n","         -4.0466e+00,  7.8838e+00, -8.6858e+00,  5.8737e-01, -4.4992e+00,\n","          4.2306e+00, -5.5376e+00, -1.9781e+01,  1.6903e+01, -1.0569e+01,\n","          1.0230e+01,  3.7584e+00, -1.1038e+01, -4.2324e+00,  6.7886e-01,\n","         -6.3693e+00, -1.4323e+01],\n","        [-2.6380e+01, -6.7123e+00, -8.3236e+00,  3.8351e+00, -5.4514e+00,\n","         -1.0285e+01,  1.4933e+00,  8.5927e+00,  5.0584e+00, -2.5851e+00,\n","          4.7064e+00,  1.0157e+01, -2.8649e+00, -1.0909e+01, -3.4554e+00,\n","          9.0989e+00, -1.7260e+01,  5.6020e+00,  9.0615e+00, -1.9827e+01,\n","         -1.7352e+00, -1.6188e+00,  1.6747e+01, -9.5343e+00,  3.1309e+00,\n","          4.5071e+00, -7.9299e+00],\n","        [-2.6450e+01, -9.0064e+00, -4.4400e+00,  6.3112e+00, -6.7911e+00,\n","         -1.1045e+01, -1.2670e+00,  3.3846e+00, -3.3919e+00,  2.3212e+00,\n","          3.4203e+00,  1.6081e+01, -5.6990e+00, -5.5314e+00, -5.1195e+00,\n","          3.8596e+00, -1.3505e+01,  3.2080e+00,  7.6421e+00, -1.4428e+01,\n","         -1.0584e+00,  3.4514e+00,  1.0501e+01, -9.2136e+00,  5.6286e-01,\n","          2.9507e+00, -8.2523e+00],\n","        [-7.6892e+00, -1.2921e+01, -5.5874e-01, -3.7206e+00, -1.2567e+01,\n","         -5.1561e+00, -5.2286e+00,  1.7415e-02,  3.4478e+00,  4.2923e-01,\n","         -2.6775e+00,  6.2969e+00, -1.4304e+00, -7.0164e+00,  1.5239e+01,\n","          6.2397e+00, -1.2713e+01, -5.9553e+00,  1.2132e+00, -9.0699e+00,\n","         -1.8321e+01, -4.2600e+00, -4.9258e-01,  4.9596e+00, -5.9961e+00,\n","          8.1291e+00, -4.1215e+00],\n","        [-1.7913e+01, -1.0138e+01, -9.8216e-01, -4.3482e+00, -1.5032e+01,\n","         -9.7372e+00, -5.3420e+00,  1.2569e+00,  7.1023e+00,  7.4709e-01,\n","          4.0801e+00, -2.7767e+00, -4.2228e+00, -1.4514e+01,  9.8028e+00,\n","          2.6729e+00, -6.9398e+00, -5.5507e+00,  2.2891e-01, -1.5515e+01,\n","         -1.0185e+01, -6.4109e+00, -1.9334e+00,  9.5875e+00,  5.7652e-02,\n","         -3.6159e+00, -7.5658e+00],\n","        [-2.5502e+01, -4.2544e+00, -2.8772e+00,  7.3612e-01, -1.6015e+01,\n","         -1.5796e+01, -8.3914e+00, -3.9589e+00,  6.0915e+00,  1.4071e+00,\n","          5.0418e+00,  3.4954e+00, -6.2634e+00, -1.5554e+01,  2.3140e+00,\n","          5.1081e+00, -1.2085e+01, -1.3609e+01,  4.6351e+00, -2.1850e+01,\n","         -4.4540e-01, -1.2373e+00,  8.6945e-01, -1.4750e+00, -1.8298e+00,\n","         -7.2848e-01, -1.5909e+01],\n","        [-2.7649e+01, -6.1782e+00, -9.5651e+00,  4.5867e+00, -8.6627e+00,\n","         -1.0316e+01, -1.2057e+00,  6.2388e+00,  4.9811e+00, -2.4797e+00,\n","          4.5546e+00,  1.1652e+01, -5.2243e+00, -9.3027e+00, -4.6504e+00,\n","          7.7576e+00, -1.5822e+01,  6.6883e-02,  1.1540e+01, -2.1362e+01,\n","         -3.5170e-01,  1.0025e+00,  1.4000e+01, -1.1879e+01,  2.1620e+00,\n","          3.1593e+00, -8.7662e+00]])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["logits = h @ W2 + b\n","logits"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([16, 27])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["logits.shape"]},{"cell_type":"markdown","metadata":{},"source":["### implementing our negative log likelihood loss"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([16, 27])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["counts = logits.exp()\n","prob = counts / counts.sum(1, keepdim=True)\n","prob.shape"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([1.3864e-09, 5.6370e-10, 1.1699e-08, 9.0034e-11, 6.5516e-14, 1.2332e-04,\n","        4.7026e-07, 5.6629e-02, 4.1453e-01, 6.3160e-07, 6.4638e-11, 3.3674e-19,\n","        5.8819e-13, 4.2594e-06, 1.5457e-05, 6.9038e-19])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["probs = prob[torch.arange(len(Y)), Y]\n","probs"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(19.6538)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["loss = -probs.log().mean()\n","loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP9t5JITPjbvYZp1vLK+VGG","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
